{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heloc_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for 'ExternalRiskEstimate' and 'NumInqLast6Mexcl7days' the coefficients are positive so a input number is better bc it gets you closer to one\n",
    "* for all columns in between the coef is negative so a small number is better bc it gets you closer to one\n",
    "* to make it uniform I turned the ranges of 'ExternalRiskEstimate' and 'NumInqLast6Mexcl7days' to be negative and made it so the input value becomes negative if it is positive that way the less than the first value in each range is better. For example, 'ExternalRiskEstimate' produces a range of [74,68] which I turned into [-74,-68]. If a person then inputs a value of 80, it becomes -80 which is less than 74 and thus better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your value: 80\n",
      "Enter the parameter : ExternalRiskEstimate\n",
      "safe\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "\n",
    "d={}\n",
    "\n",
    "cols=['ExternalRiskEstimate', 'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec', 'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumInqLast6M', 'NumInqLast6Mexcl7days']\n",
    "for i in cols:\n",
    "    percentiles = pd.Series(df[i])\n",
    "    x=percentiles.quantile([.4,.6])\n",
    "    vals = x.values                            \n",
    "    if i==cols[0] or i==cols[6]:\n",
    "         d[i]=[-1*vals[1],-1*vals[0]]\n",
    "    else:\n",
    "        d[i]=[vals[0],vals[1]]\n",
    "\n",
    "                                \n",
    "val = input(\"Enter your value: \") \n",
    "val=int(val)\n",
    "param = input(\"Enter the parameter : \") \n",
    "if param=='ExternalRiskEstimate' or param== 'NumInqLast6Mexcl7days':\n",
    "    if val ==abs(val):\n",
    "        val=val*-1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in cols:\n",
    "    if param==i:\n",
    "        if val<d[i][0]:\n",
    "            print (\"safe\")\n",
    "        elif val>d[i][1]:\n",
    "            print (\"risky\")\n",
    "        else:\n",
    "            print(\"neutral\")\n",
    "    else:\n",
    "        break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_y(row):\n",
    "    if row['RiskPerformance'] == 'Good':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df.apply(lambda row: label_y(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['RiskPerformance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    \n",
    "# The function `init_classifiers` returns a list of classifiers to be trained on the datasets\n",
    "def init_classifiers():\n",
    "    return([(SVC(), model_names[0], param_grid_svc), \n",
    "            (LogisticRegression(), model_names[1], param_grid_logistic),\n",
    "            (KNeighborsClassifier(), model_names[2], param_grid_knn),\n",
    "            (GaussianNB(), model_names[3], param_grid_nb),\n",
    "            (DecisionTreeClassifier(), model_names[4], param_grid_tree),\n",
    "            (RandomForestClassifier(), model_names[6], param_grid_rf),\n",
    "            (AdaBoostClassifier(), model_names[7], param_grid_boost)\n",
    "           ])\n",
    "\n",
    "# 'model_names' contains the names  that we will use for the above classifiers\n",
    "model_names = ['SVM','LR','KNN','NB','Tree','QDA','RF','Boosting']\n",
    "\n",
    "# the training parameters of each model\n",
    "param_grid_svc = [{'C':[0.1,1],'kernel':['rbf','linear'], 'max_iter':[-1],'random_state':[1]}]\n",
    "param_grid_logistic = [{'C':[0.1,1], 'penalty':['l1','l2'],'random_state':[1]}]\n",
    "param_grid_knn = [{},{'n_neighbors':[1,2,3,4]}]\n",
    "param_grid_nb = [{}]\n",
    "param_grid_tree = [{'random_state':[1]},{'criterion':['gini'], 'max_depth':[2,3], 'min_samples_split':[3,5],'random_state':[1]}]\n",
    "param_grid_rf = [{'random_state':[1]},{'n_estimators':[10,30],'max_features':[0.2, 0.3], 'bootstrap':[True],'random_state':[1]}]\n",
    "param_grid_boost = [{'random_state':[1]},{'n_estimators':[10,20],'learning_rate':[0.1,1],'random_state':[1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis= 1)\n",
    "\n",
    "Y = df['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = init_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "    clf = GridSearchCV(model[0],model[2],cv = 2)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Model ', model)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Accuracy ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
