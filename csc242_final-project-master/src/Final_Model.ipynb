{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import linear_model, metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heloc_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10459"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_y(row):\n",
    "    if row['RiskPerformance'] == 'Good':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df.apply(lambda row: label_y(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['RiskPerformance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    \n",
    "# The function `init_classifiers` returns a list of classifiers to be trained on the datasets\n",
    "def init_classifiers():\n",
    "    return([(SVC(), model_names[0], param_grid_svc), \n",
    "            (LogisticRegression(), model_names[1], param_grid_logistic),\n",
    "            (KNeighborsClassifier(), model_names[2], param_grid_knn),\n",
    "            (GaussianNB(), model_names[3], param_grid_nb),\n",
    "            (DecisionTreeClassifier(), model_names[4], param_grid_tree),\n",
    "            (RandomForestClassifier(), model_names[6], param_grid_rf),\n",
    "            (AdaBoostClassifier(), model_names[7], param_grid_boost)\n",
    "           ])\n",
    "\n",
    "# 'model_names' contains the names  that we will use for the above classifiers\n",
    "model_names = ['SVM','LR','KNN','NB','Tree','QDA','RF','Boosting']\n",
    "\n",
    "# the training parameters of each model\n",
    "param_grid_svc = [{'C':[0.1,1],'kernel':['rbf','linear'], 'max_iter':[-1],'random_state':[1]}]\n",
    "param_grid_logistic = [{'C':[0.1,1], 'penalty':['l1','l2'],'random_state':[1]}]\n",
    "param_grid_knn = [{},{'n_neighbors':[1,2,3,4]}]\n",
    "param_grid_nb = [{}]\n",
    "param_grid_tree = [{'random_state':[1]},{'criterion':['gini'], 'max_depth':[2,3], 'min_samples_split':[3,5],'random_state':[1]}]\n",
    "param_grid_rf = [{'random_state':[1]},{'n_estimators':[10,30],'max_features':[0.2, 0.3], 'bootstrap':[True],'random_state':[1]}]\n",
    "param_grid_boost = [{'random_state':[1]},{'n_estimators':[10,20],'learning_rate':[0.1,1],'random_state':[1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "# The function `init_classifiers` returns a list of classifiers to be trained on the datasets\n",
    "def init_classifiers():\n",
    "    return([(SVC(), model_names[0], param_grid_svc), \n",
    "            (LogisticRegression(), model_names[1], param_grid_logistic)])\n",
    "\n",
    "# 'model_names' contains the names  that we will use for the above classifiers\n",
    "model_names = ['SVM','LR']\n",
    "\n",
    "# the training parameters of each model\n",
    "param_grid_svc = [{'C':[0.1,1],'kernel':['rbf','linear'], 'max_iter':[-1],'random_state':[1]}]\n",
    "param_grid_logistic = [{'C':[0.1,1], 'penalty':['l1','l2'],'random_state':[1]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis= 1)\n",
    "# X = X[:1000]\n",
    "Y = df['y']\n",
    "# Y = Y[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = init_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LR'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "    clf = GridSearchCV(model[0],model[2],cv = 2)\n",
    "\n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    if model[1] == 'LR':\n",
    "        coef = clf.coef_[0]\n",
    "        pos = [x for x in range(0,len(coef))]\n",
    "        plt.bar(pos,coef, align='center', alpha=0.5)\n",
    "        \n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    print('Model ', model)\n",
    "    acc = accuracy_score(Y,y_pred)\n",
    "    print('Accuracy ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using all the data, find best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis= 1)\n",
    "# X = X[:1000]\n",
    "Y = df['y']\n",
    "# Y = Y[:1000]\n",
    "\n",
    "C = [0.003, 0.01,0.03, 0.1, 0.3, 1,3,10,30,100,300,1000, 3000, 10000, 30000, 100000, 300000]\n",
    "best_acc = 0\n",
    "best_c = None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "for c in C:\n",
    "        clf = linear_model.LogisticRegression(penalty='l1', C=c, \n",
    "                                                      intercept_scaling=1, \n",
    "                                                      solver='liblinear',\n",
    "                                                      max_iter=1000)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        acc = metrics.accuracy_score(y_pred,y_test)\n",
    "        \n",
    "    #  only use new hyper parameter if better by thresh amount\n",
    "        if(acc > best_acc):\n",
    "            best_acc = acc\n",
    "            best_c = c\n",
    "\n",
    "print(best_acc)\n",
    "clf = linear_model.LogisticRegression(penalty='l1', C=best_c, \n",
    "                                                  intercept_scaling=1, \n",
    "                                                  solver='liblinear',\n",
    "                                                  max_iter=1000)\n",
    "clf.fit(X,Y)\n",
    "coef = clf.coef_[0]\n",
    "pos = [x for x in range(0,len(coef))]\n",
    "plt.bar(pos,coef, align='center', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using only the 10 heighest weights from the coefficient graph above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = [df.columns[0],df.columns[5],df.columns[6],df.columns[9],df.columns[10],df.columns[12],df.columns[15],df.columns[16],df.columns[19],df.columns[-1]]\n",
    "\n",
    "new_df =  df[usecols]\n",
    "X = new_df.drop('y', axis= 1)\n",
    "Y = new_df['y']\n",
    "\n",
    "C = [0.003, 0.01,0.03, 0.1, 0.3, 1,3,10,30,100,300,1000, 3000, 10000, 30000, 100000, 300000]\n",
    "best_acc = 0\n",
    "best_c = None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "for c in C:\n",
    "    clf = linear_model.LogisticRegression(penalty='l1', C=c, \n",
    "                                                      intercept_scaling=1, \n",
    "                                                      solver='liblinear',\n",
    "                                                      max_iter=1000)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test.values)\n",
    "    acc = metrics.accuracy_score(y_pred,y_test)\n",
    "\n",
    "#  only use new hyper parameter if better by thresh amount\n",
    "    if(acc > best_acc):\n",
    "        best_acc = acc\n",
    "        best_c = c\n",
    "\n",
    "print(best_acc)\n",
    "clf = linear_model.LogisticRegression(penalty='l1', C=best_c, \n",
    "                                                  intercept_scaling=1, \n",
    "                                                  solver='liblinear',\n",
    "                                                  max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "coef = clf.coef_[0]\n",
    "pos = [x for x in range(0,len(coef))]\n",
    "plt.bar(pos,coef, align='center', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usecols)\n",
    "len(usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrained the model with only 7 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6787762906309751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usecols = [df.columns[0],df.columns[5],df.columns[6],df.columns[9],df.columns[10],df.columns[15],df.columns[16],df.columns[-1]]\n",
    "\n",
    "new_df =  df[usecols]\n",
    "X = new_df.drop('y', axis= 1)\n",
    "# X = X[:1000]\n",
    "Y = new_df['y']\n",
    "# Y = Y[:1000]\n",
    "\n",
    "C = [0.003, 0.01,0.03, 0.1, 0.3, 1,3,10,30,100,300,1000, 3000, 10000, 30000, 100000, 300000]\n",
    "best_acc = 0\n",
    "best_c = None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "for c in C:\n",
    "        clf = linear_model.LogisticRegression(penalty='l1', C=c, \n",
    "                                                      intercept_scaling=1, \n",
    "                                                      solver='liblinear',\n",
    "                                                      max_iter=1000)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        acc = metrics.accuracy_score(y_pred,y_test)\n",
    "        \n",
    "    #  only use new hyper parameter if better by thresh amount\n",
    "        if(acc > best_acc):\n",
    "            best_acc = acc\n",
    "            best_c = c\n",
    "\n",
    "print(best_acc)\n",
    "clf = linear_model.LogisticRegression(penalty='l1', C=best_c, \n",
    "                                                  intercept_scaling=1, \n",
    "                                                  solver='liblinear',\n",
    "                                                  max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "coef = clf.coef_[0]\n",
    "pos = [x for x in range(0,len(coef))]\n",
    "plt.bar(pos,coef, align='center', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses sklearns built in method to select features and retrain model to find performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=7)\n",
    "selector.fit(X, Y)\n",
    "# Get columns to keep\n",
    "cols = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_cols = []\n",
    "for col in cols:\n",
    "    sklearn_cols.append(df.columns[col])\n",
    "sklearn_cols.append('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =  df[sklearn_cols]\n",
    "X = new_df.drop('y', axis= 1)\n",
    "# X = X[:1000]\n",
    "Y = new_df['y']\n",
    "# Y = Y[:1000]\n",
    "\n",
    "C = [0.003, 0.01,0.03, 0.1, 0.3, 1,3,10,30,100,300,1000, 3000, 10000, 30000, 100000, 300000]\n",
    "best_acc = 0\n",
    "best_c = None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "for c in C:\n",
    "        clf = linear_model.LogisticRegression(penalty='l1', C=c, \n",
    "                                                      intercept_scaling=1, \n",
    "                                                      solver='liblinear',\n",
    "                                                      max_iter=1000)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test.values)\n",
    "        acc = metrics.accuracy_score(y_pred,y_test)\n",
    "        \n",
    "    #  only use new hyper parameter if better by thresh amount\n",
    "        if(acc > best_acc):\n",
    "            best_acc = acc\n",
    "            best_c = c\n",
    "\n",
    "print(best_acc)\n",
    "clf = linear_model.LogisticRegression(penalty='l1', C=best_c, \n",
    "                                                  intercept_scaling=1, \n",
    "                                                  solver='liblinear',\n",
    "                                                  max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "coef = clf.coef_[0]\n",
    "pos = [x for x in range(0,len(coef))]\n",
    "plt.bar(pos,coef, align='center', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain model on all data and test on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(new_df[usecols[:-1]].values,new_df[usecols[-1]].values)\n",
    "sample_test = [[60,2,1,4,5,2,0]]\n",
    "clf.predict(sample_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heloc_dataset_v1.csv')\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "data_cutoffs = {}\n",
    "\n",
    "cols = ['ExternalRiskEstimate', 'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec', 'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumInqLast6M', 'NumInqLast6Mexcl7days']\n",
    "for i in cols:\n",
    "#     print(df[i].describe())\n",
    "    percentiles = pd.Series(df[i])\n",
    "    x = percentiles.quantile([.4,.6])\n",
    "    vals = x.values                            \n",
    "    if i == cols[0] or i == cols[6]:\n",
    "         data_cutoffs[i] = [-1 * vals[1], -1 * vals[0]]\n",
    "    else:\n",
    "        data_cutoffs[i] = [vals[0], vals[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%python\n",
    "from tkinter import Tk, Label, Button, Entry, IntVar, StringVar, END, W, E\n",
    "\n",
    "class Calculator:\n",
    "\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Sub Prime Mortgage\")\n",
    "        vcmd = master.register(self.validate) # we have to wrap the command\n",
    "        \n",
    "        # LISTS TO CONTAIN REFERENCES TO WIDGETS\n",
    "        self.param_values = list()\n",
    "        self.param_value_types = list()\n",
    "        self.param_labels = list()\n",
    "        self.param_entries = list()\n",
    "        \n",
    "        # CREATING WIDGETS (ENTRIES AND LABELS)\n",
    "        for var in cols:\n",
    "            param_value = 0\n",
    "            param_label = Label(master, text=var)\n",
    "            param = IntVar()\n",
    "            param.set(param_value)\n",
    "            param_entry = Entry(master, validate=\"key\", validatecommand=(vcmd, '%P'))\n",
    "            \n",
    "            self.param_values.append(param_value)\n",
    "            self.param_labels.append(param_label)\n",
    "            self.param_value_types.append(param)\n",
    "            self.param_entries.append(param_entry)\n",
    "        \n",
    "        self.result_label_text = StringVar()\n",
    "        self.result_label = Label(master, textvariable=self.result_label_text)\n",
    "        self.submit_button = Button(master, text=\"Submit\", command=lambda: self.update(\"submit\"))\n",
    "        \n",
    "        # LAYOUT\n",
    "        for i in range(0, len(self.param_labels)):\n",
    "            self.param_labels[i].grid(row=i, column=0, sticky=W)\n",
    "            self.param_entries[i].grid(row=i, column=1, columnspan=2, sticky=E)\n",
    "        self.submit_button.grid(row=len(self.param_entries), column=1)\n",
    "        self.result_label.grid(row=len(self.param_entries) + 1, column=1)\n",
    "\n",
    "    def validate(self, new_text):\n",
    "        if not new_text: # the field is being cleared\n",
    "            self.entered_number = 0\n",
    "            return True \n",
    "        try:\n",
    "            self.entered_number = int(new_text)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def update_background_color(self):\n",
    "        i = 0\n",
    "        for entry in self.param_entries:\n",
    "            param = cols[i]\n",
    "            threshold = data_cutoffs[param]\n",
    "            entry_value = float(entry.get())\n",
    "            \n",
    "            # case where coefficients are positive\n",
    "            if param == 'ExternalRiskEstimate' or param == 'NumInqLast6Mexcl7days':\n",
    "                entry_value = entry_value * -1 if entry_value == abs(entry_value) else entry_value\n",
    "\n",
    "            if entry_value < threshold[0]:\n",
    "                entry.config({\"background\": \"#baef56\"}) # green\n",
    "            elif entry_value < threshold[1]:\n",
    "                entry.config({\"background\": \"#fffd9b\"}) # yellow\n",
    "            else:\n",
    "                entry.config({\"background\": \"#f7c0c0\"}) # red\n",
    "            i = i + 1\n",
    "    \n",
    "    def update_result_label(self):\n",
    "        entry_vals = [[float(entry.get()) for entry in self.param_entries]]\n",
    "        prediction = clf.predict(entry_vals)[0]\n",
    "        self.result_label_text.set(\"Result: \" + str(prediction))\n",
    "\n",
    "    def update(self, method):\n",
    "        if method == \"submit\":\n",
    "            self.update_background_color()\n",
    "            self.update_result_label()            \n",
    "                \n",
    "root = Tk()\n",
    "my_gui = Calculator(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
