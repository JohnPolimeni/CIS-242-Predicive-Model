{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heloc_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ExternalRiskEstimate': [68.0, 74.0], 'NumTrades60Ever2DerogPubRec': [0.0, 0.0], 'NumTrades90Ever2DerogPubRec': [0.0, 0.0], 'MaxDelq2PublicRecLast12M': [7.0, 6.0], 'MaxDelqEver': [8.0, 6.0], 'NumInqLast6M': [1.0, 0.0], 'NumInqLast6Mexcl7days': [0.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(df)\n",
    "\n",
    "data_cutoffs = {}\n",
    "\n",
    "cols=['ExternalRiskEstimate', 'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec', 'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumInqLast6M', 'NumInqLast6Mexcl7days']\n",
    "for i in cols:\n",
    "    percentiles = pd.Series(df[i])\n",
    "    x=percentiles.quantile([.4,.6])\n",
    "    vals = x.values                            \n",
    "    if i==cols[0] or i==cols[6]:\n",
    "         data_cutoffs[i]=[vals[0],vals[1]]\n",
    "\n",
    "    else:\n",
    "        data_cutoffs[i]=[vals[1],vals[0]]\n",
    "\n",
    "print(data_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_y(row):\n",
    "    if row['RiskPerformance'] == 'Good':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df.apply(lambda row: label_y(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['RiskPerformance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    \n",
    "# The function `init_classifiers` returns a list of classifiers to be trained on the datasets\n",
    "def init_classifiers():\n",
    "    return([(SVC(), model_names[0], param_grid_svc), \n",
    "            (LogisticRegression(), model_names[1], param_grid_logistic),\n",
    "            (KNeighborsClassifier(), model_names[2], param_grid_knn),\n",
    "            (GaussianNB(), model_names[3], param_grid_nb),\n",
    "            (DecisionTreeClassifier(), model_names[4], param_grid_tree),\n",
    "            (RandomForestClassifier(), model_names[6], param_grid_rf),\n",
    "            (AdaBoostClassifier(), model_names[7], param_grid_boost)\n",
    "           ])\n",
    "\n",
    "# 'model_names' contains the names  that we will use for the above classifiers\n",
    "model_names = ['SVM','LR','KNN','NB','Tree','QDA','RF','Boosting']\n",
    "\n",
    "# the training parameters of each model\n",
    "param_grid_svc = [{'C':[0.1,1],'kernel':['rbf','linear'], 'max_iter':[-1],'random_state':[1]}]\n",
    "param_grid_logistic = [{'C':[0.1,1], 'penalty':['l1','l2'],'random_state':[1]}]\n",
    "param_grid_knn = [{},{'n_neighbors':[1,2,3,4]}]\n",
    "param_grid_nb = [{}]\n",
    "param_grid_tree = [{'random_state':[1]},{'criterion':['gini'], 'max_depth':[2,3], 'min_samples_split':[3,5],'random_state':[1]}]\n",
    "param_grid_rf = [{'random_state':[1]},{'n_estimators':[10,30],'max_features':[0.2, 0.3], 'bootstrap':[True],'random_state':[1]}]\n",
    "param_grid_boost = [{'random_state':[1]},{'n_estimators':[10,20],'learning_rate':[0.1,1],'random_state':[1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y', axis= 1)\n",
    "X = X[:1000]\n",
    "Y = df['y']\n",
    "Y = Y[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = init_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  (SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'SVM', [{'C': [0.1, 1], 'kernel': ['rbf', 'linear'], 'max_iter': [-1], 'random_state': [1]}])\n",
      "Accuracy  0.74\n",
      "Model  (LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'LR', [{'C': [0.1, 1], 'penalty': ['l1', 'l2'], 'random_state': [1]}])\n",
      "Accuracy  0.728\n",
      "Model  (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'), 'KNN', [{}, {'n_neighbors': [1, 2, 3, 4]}])\n",
      "Accuracy  0.66\n",
      "Model  (GaussianNB(priors=None), 'NB', [{}])\n",
      "Accuracy  0.688\n",
      "Model  (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'Tree', [{'random_state': [1]}, {'criterion': ['gini'], 'max_depth': [2, 3], 'min_samples_split': [3, 5], 'random_state': [1]}])\n",
      "Accuracy  0.664\n",
      "Model  (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'RF', [{'random_state': [1]}, {'n_estimators': [10, 30], 'max_features': [0.2, 0.3], 'bootstrap': [True], 'random_state': [1]}])\n",
      "Accuracy  0.68\n",
      "Model  (AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), 'Boosting', [{'random_state': [1]}, {'n_estimators': [10, 20], 'learning_rate': [0.1, 1], 'random_state': [1]}])\n",
      "Accuracy  0.672\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y)\n",
    "\n",
    "    clf = GridSearchCV(model[0],model[2],cv = 2)\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Model ', model)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Accuracy ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
